{
  "title": "High-Fidelity Image Generation With Fewer Labels",
  "authors": [
    "Mario Lucic",
    "Michael Tschannen",
    "Marvin Ritter",
    "Xiaohua Zhai",
    "Olivier Bachem",
    "Sylvain Gelly"
  ],
  "abstract": "Deep generative models are becoming a cornerstone of modern machine learning.\nRecent work on conditional generative adversarial networks has shown that\nlearning complex, high-dimensional distributions over natural images is within\nreach. While the latest models are able to generate high-fidelity, diverse\nnatural images at high resolution, they rely on a vast quantity of labeled\ndata. In this work we demonstrate how one can benefit from recent work on self-\nand semi-supervised learning to outperform state-of-the-art (SOTA) on both\nunsupervised ImageNet synthesis, as well as in the conditional setting. In\nparticular, the proposed approach is able to match the sample quality (as\nmeasured by FID) of the current state-of-the art conditional model BigGAN on\nImageNet using only 10% of the labels and outperform it using 20% of the\nlabels.",
  "id": "arxiv.1903.02271",
  "url": "https://arxiv.org/abs/1903.02271",
  "pdf": "https://arxiv.org/pdf/1903.02271",
  "bibtex": "@misc{lucic2019_arxiv:1903.02271,\n    title = {High-Fidelity Image Generation With Fewer Labels},\n    author = {Mario Lucic, Michael Tschannen, Marvin Ritter, Xiaohua Zhai, Olivier Bachem, Sylvain Gelly},\n    year = {2019},\n    archiveprefix = {arXiv},\n    eprint = {1903.02271},\n    pdf = {https://arxiv.org/pdf/1903.02271},\n    url = https://arxiv.org/abs/1903.02271\n}",
  "source": "arxiv.org",
  "date": 1552325306,
  "tags": []
}