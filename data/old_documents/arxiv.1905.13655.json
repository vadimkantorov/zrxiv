{
  "title": "Implicit Regularization in Deep Matrix Factorization",
  "authors": [
    "Sanjeev Arora",
    "Nadav Cohen",
    "Wei Hu",
    "Yuping Luo"
  ],
  "abstract": "Efforts to understand the generalization mystery in deep learning have led to\nthe belief that gradient-based optimization induces a form of implicit\nregularization, a bias towards models of low \"complexity.\" We study the\nimplicit regularization of gradient descent over deep linear neural networks\nfor matrix completion and sensing, a model referred to as deep matrix\nfactorization. Our first finding, supported by theory and experiments, is that\nadding depth to a matrix factorization enhances an implicit tendency towards\nlow-rank solutions, oftentimes leading to more accurate recovery. Secondly, we\npresent theoretical and empirical arguments questioning a nascent view by which\nimplicit regularization in matrix factorization can be captured using simple\nmathematical norms. Our results point to the possibility that the language of\nstandard regularizers may not be rich enough to fully encompass the implicit\nregularization brought forth by gradient-based optimization.",
  "id": "arxiv.1905.13655",
  "url": "https://arxiv.org/abs/1905.13655",
  "pdf": "https://arxiv.org/pdf/1905.13655",
  "bibtex": "@misc{arora2019_arxiv:1905.13655,\n    title = {Implicit Regularization in Deep Matrix Factorization},\n    author = {Sanjeev Arora and Nadav Cohen and Wei Hu and Yuping Luo},\n    year = {2019},\n    archiveprefix = {arXiv},\n    eprint = {1905.13655},\n    pdf = {https://arxiv.org/pdf/1905.13655},\n    url = {https://arxiv.org/abs/1905.13655}\n}",
  "source": "arxiv.org",
  "date": 1563042225,
  "tags": [],
  "api": "https://export.arxiv.org/api/query?id_list=1905.13655"
}