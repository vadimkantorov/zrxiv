{
  "title": "Pixels to Graphs by Associative Embedding",
  "author": [
    "Alejandro Newell",
    "Jia Deng"
  ],
  "abstract": "  Graphs are a useful abstraction of image content. Not only can graphs\nrepresent details about individual objects in a scene but they can capture the\ninteractions between pairs of objects. We present a method for training a\nconvolutional neural network such that it takes in an input image and produces\na full graph definition. This is done end-to-end in a single stage with the use\nof associative embeddings. The network learns to simultaneously identify all of\nthe elements that make up a graph and piece them together. We benchmark on the\nVisual Genome dataset, and demonstrate state-of-the-art performance on the\nchallenging task of scene graph generation.\n",
  "id": "1706.07365",
  "date": 1541591055,
  "url": "https://arxiv.org/abs/1706.07365",
  "tags": [
    "giant"
  ]
}