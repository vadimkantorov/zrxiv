{
  "title": "Hierarchical Neural Story Generation",
  "authors": [
    "Angela Fan",
    "Mike Lewis",
    "Yann Dauphin"
  ],
  "abstract": "  We explore story generation: creative systems that can build coherent and\nfluent passages of text about a topic. We collect a large dataset of 300K\nhuman-written stories paired with writing prompts from an online forum. Our\ndataset enables hierarchical story generation, where the model first generates\na premise, and then transforms it into a passage of text. We gain further\nimprovements with a novel form of model fusion that improves the relevance of\nthe story to the prompt, and adding a new gated multi-scale self-attention\nmechanism to model long-range context. Experiments show large improvements over\nstrong baselines on both automated and human evaluations. Human judges prefer\nstories generated by our approach to those from a strong non-hierarchical model\nby a factor of two to one.\n",
  "id": "arxiv.1805.04833",
  "url": "https://arxiv.org/abs/1805.04833",
  "pdf": "https://arxiv.org/pdf/1805.04833",
  "bibtex": "@misc{fan2018_arxiv:1805.04833,\n    title = {Hierarchical Neural Story Generation},\n    author = {Angela Fan, Mike Lewis, Yann Dauphin},\n    year = {2018},\n    archiveprefix = {arXiv},\n    eprint = {1805.04833},\n    pdf = {https://arxiv.org/pdf/1805.04833},\n    url = {https://arxiv.org/abs/1805.04833}\n}",
  "source": "arxiv.org",
  "date": 1550509968,
  "tags": []
}