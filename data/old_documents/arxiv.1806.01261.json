{
  "title": "Relational inductive biases, deep learning, and graph networks",
  "authors": [
    "Peter W. Battaglia",
    "Jessica B. Hamrick",
    "Victor Bapst",
    "Alvaro Sanchez-Gonzalez",
    "Vinicius Zambaldi",
    "Mateusz Malinowski",
    "Andrea Tacchetti",
    "David Raposo",
    "Adam Santoro",
    "Ryan Faulkner",
    "Caglar Gulcehre",
    "Francis Song",
    "Andrew Ballard",
    "Justin Gilmer",
    "George Dahl",
    "Ashish Vaswani",
    "Kelsey Allen",
    "Charles Nash",
    "Victoria Langston",
    "Chris Dyer",
    "Nicolas Heess",
    "Daan Wierstra",
    "Pushmeet Kohli",
    "Matt Botvinick",
    "Oriol Vinyals",
    "Yujia Li",
    "Razvan Pascanu"
  ],
  "abstract": "Artificial intelligence (AI) has undergone a renaissance recently, making\nmajor progress in key domains such as vision, language, control, and\ndecision-making. This has been due, in part, to cheap data and cheap compute\nresources, which have fit the natural strengths of deep learning. However, many\ndefining characteristics of human intelligence, which developed under much\ndifferent pressures, remain out of reach for current approaches. In particular,\ngeneralizing beyond one's experiences--a hallmark of human intelligence from\ninfancy--remains a formidable challenge for modern AI.\n  The following is part position paper, part review, and part unification. We\nargue that combinatorial generalization must be a top priority for AI to\nachieve human-like abilities, and that structured representations and\ncomputations are key to realizing this objective. Just as biology uses nature\nand nurture cooperatively, we reject the false choice between\n\"hand-engineering\" and \"end-to-end\" learning, and instead advocate for an\napproach which benefits from their complementary strengths. We explore how\nusing relational inductive biases within deep learning architectures can\nfacilitate learning about entities, relations, and rules for composing them. We\npresent a new building block for the AI toolkit with a strong relational\ninductive bias--the graph network--which generalizes and extends various\napproaches for neural networks that operate on graphs, and provides a\nstraightforward interface for manipulating structured knowledge and producing\nstructured behaviors. We discuss how graph networks can support relational\nreasoning and combinatorial generalization, laying the foundation for more\nsophisticated, interpretable, and flexible patterns of reasoning. As a\ncompanion to this paper, we have released an open-source software library for\nbuilding graph networks, with demonstrations of how to use them in practice.",
  "id": "arxiv.1806.01261",
  "url": "https://arxiv.org/abs/1806.01261",
  "pdf": "https://arxiv.org/pdf/1806.01261",
  "bibtex": "@misc{battaglia2018_arxiv:1806.01261,\n    title = {Relational inductive biases, deep learning, and graph networks},\n    author = {Peter W. Battaglia and Jessica B. Hamrick and Victor Bapst and Alvaro Sanchez-Gonzalez and Vinicius Zambaldi and Mateusz Malinowski and Andrea Tacchetti and David Raposo and Adam Santoro and Ryan Faulkner and Caglar Gulcehre and Francis Song and Andrew Ballard and Justin Gilmer and George Dahl and Ashish Vaswani and Kelsey Allen and Charles Nash and Victoria Langston and Chris Dyer and Nicolas Heess and Daan Wierstra and Pushmeet Kohli and Matt Botvinick and Oriol Vinyals and Yujia Li and Razvan Pascanu},\n    year = {2018},\n    archiveprefix = {arXiv},\n    eprint = {1806.01261},\n    pdf = {https://arxiv.org/pdf/1806.01261},\n    url = {https://arxiv.org/abs/1806.01261}\n}",
  "source": "arxiv.org",
  "date": 1560689122,
  "tags": [],
  "api": "https://export.arxiv.org/api/query?id_list=1806.01261"
}