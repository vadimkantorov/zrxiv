{
  "title": "Capsule Graph Neural Network",
  "authors": [
    "Anonymous"
  ],
  "abstract": "The high-quality node embeddings learned from the Graph Neural Networks (GNNs) have been applied to a wide range of node-based applications and some of them have achieved state-of-the-art (SOTA) performance. However, when applying node embeddings learned from GNNs to generate graph embeddings, the scalar node representation may not suffice to preserve the node/graph properties efficiently, resulting in sub-optimal graph embeddings.\n\nInspired by the Capsule Neural Network (CapsNet), we propose the Capsule Graph Neural Network (CapsGNN), which adopts the concept of capsules to address the weakness in existing GNN-based graph embeddings algorithms. By extracting node features in the form of capsules, routing mechanism can be utilized to capture important information at the graph level. As a result, our model generates multiple embeddings for each graph to capture graph properties from different aspects. The attention module incorporated in CapsGNN is used to tackle graphs with various sizes which also enables the model to focus on critical parts of the graphs.\n\nOur extensive evaluations with 10 graph-structured datasets demonstrate that CapsGNN has a powerful mechanism that operates to capture macroscopic properties of the whole graph by data-driven. It outperforms other SOTA techniques on several graph classification tasks, by virtue of the new instrument.",
  "id": "openreview.Byl8BnRcYm",
  "url": "https://openreview.net/forum?id=Byl8BnRcYm",
  "pdf": "https://openreview.net/pdf/85968e1741e4f0418aed4e5f425c80de60feb8ac.pdf",
  "bibtex": "@inproceedings{\n  anonymous2019capsules,\n  title={Capsules Graph Neural Network},\n  author={Anonymous},\n  booktitle={Submitted to International Conference on Learning Representations},\n  year={2019},\n  url={https://openreview.net/forum?id=Byl8BnRcYm},\n  note={under review}\n}",
  "source": "openreview.net",
  "date": 1545185729,
  "tags": []
}