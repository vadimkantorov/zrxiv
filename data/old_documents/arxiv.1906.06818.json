{
  "title": "Stacked Capsule Autoencoders",
  "authors": [
    "Adam R. Kosiorek",
    "Sara Sabour",
    "Yee Whye Teh",
    "Geoffrey E. Hinton"
  ],
  "abstract": "An object can be seen as a geometrically organized set of interrelated parts.\nA system that makes explicit use of these geometric relationships to recognize\nobjects should be naturally robust to changes in viewpoint, because the\nintrinsic geometric relationships are viewpoint-invariant. We describe an\nunsupervised version of capsule networks, in which a neural encoder, which\nlooks at all of the parts, is used to infer the presence and poses of object\ncapsules. The encoder is trained by backpropagating through a decoder, which\npredicts the pose of each already discovered part using a mixture of pose\npredictions. The parts are discovered directly from an image, in a similar\nmanner, by using a neural encoder, which infers parts and their affine\ntransformations. The corresponding decoder models each image pixel as a mixture\nof predictions made by affine-transformed parts. We learn object- and their\npart-capsules on unlabeled data, and then cluster the vectors of presences of\nobject capsules. When told the names of these clusters, we achieve\nstate-of-the-art results for unsupervised classification on SVHN (55%) and near\nstate-of-the-art on MNIST (98.5%).",
  "id": "arxiv.1906.06818",
  "url": "https://arxiv.org/abs/1906.06818",
  "pdf": "https://arxiv.org/pdf/1906.06818",
  "bibtex": "@misc{kosiorek2019_arxiv:1906.06818,\n    title = {Stacked Capsule Autoencoders},\n    author = {Adam R. Kosiorek and Sara Sabour and Yee Whye Teh and Geoffrey E. Hinton},\n    year = {2019},\n    archiveprefix = {arXiv},\n    eprint = {1906.06818},\n    pdf = {https://arxiv.org/pdf/1906.06818},\n    url = {https://arxiv.org/abs/1906.06818}\n}",
  "source": "arxiv.org",
  "date": 1562703332,
  "tags": [],
  "api": "https://export.arxiv.org/api/query?id_list=1906.06818"
}