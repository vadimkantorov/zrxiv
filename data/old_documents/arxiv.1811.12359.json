{
  "title": "Challenging Common Assumptions in the Unsupervised Learning of\n  Disentangled Representations",
  "author": [
    "Francesco Locatello",
    "Stefan Bauer",
    "Mario Lucic",
    "Sylvain Gelly",
    "Bernhard Sch√∂lkopf",
    "Olivier Bachem"
  ],
  "abstract": "  In recent years, the interest in unsupervised learning of disentangled\nrepresentations has significantly increased. The key assumption is that\nreal-world data is generated by a few explanatory factors of variation and that\nthese factors can be recovered by unsupervised learning algorithms. A large\nnumber of unsupervised learning approaches based on auto-encoding and\nquantitative evaluation metrics of disentanglement have been proposed; yet, the\nefficacy of the proposed approaches and utility of proposed notions of\ndisentanglement has not been challenged in prior work. In this paper, we\nprovide a sober look on recent progress in the field and challenge some common\nassumptions.\n  We first theoretically show that the unsupervised learning of disentangled\nrepresentations is fundamentally impossible without inductive biases on both\nthe models and the data. Then, we train more than 12000 models covering the six\nmost prominent methods, and evaluate them across six disentanglement metrics in\na reproducible large-scale experimental study on seven different data sets. On\nthe positive side, we observe that different methods successfully enforce\nproperties `encouraged' by the corresponding losses. On the negative side, we\nobserve that in our study (1) `good' hyperparameters seemingly cannot be\nidentified without access to ground-truth labels, (2) good hyperparameters\nneither transfer across data sets nor across disentanglement metrics, and (3)\nthat increased disentanglement does not seem to lead to a decreased sample\ncomplexity of learning for downstream tasks.\n  These results suggest that future work on disentanglement learning should be\nexplicit about the role of inductive biases and (implicit) supervision,\ninvestigate concrete benefits of enforcing disentanglement of the learned\nrepresentations, and consider a reproducible experimental setup covering\nseveral data sets.\n",
  "id": "arxiv.1811.12359",
  "url": "https://arxiv.org/abs/1811.12359",
  "pdf": "https://arxiv.org/pdf/1811.12359",
  "source": "arxiv.org",
  "date": 1543612359,
  "tags": []
}