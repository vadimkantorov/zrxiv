{
  "title": "GANSynth: Adversarial Neural Audio Synthesis",
  "authors": [
    "Jesse Engel",
    "Kumar Krishna Agrawal",
    "Shuo Chen",
    "Ishaan Gulrajani",
    "Chris Donahue",
    "Adam Roberts"
  ],
  "abstract": "Efficient audio synthesis is an inherently difficult machine learning task,\nas human perception is sensitive to both global structure and fine-scale\nwaveform coherence. Autoregressive models, such as WaveNet, model local\nstructure at the expense of global latent structure and slow iterative\nsampling, while Generative Adversarial Networks (GANs), have global latent\nconditioning and efficient parallel sampling, but struggle to generate\nlocally-coherent audio waveforms. Herein, we demonstrate that GANs can in fact\ngenerate high-fidelity and locally-coherent audio by modeling log magnitudes\nand instantaneous frequencies with sufficient frequency resolution in the\nspectral domain. Through extensive empirical investigations on the NSynth\ndataset, we demonstrate that GANs are able to outperform strong WaveNet\nbaselines on automated and human evaluation metrics, and efficiently generate\naudio several orders of magnitude faster than their autoregressive\ncounterparts.",
  "id": "arxiv.1902.08710",
  "url": "https://arxiv.org/abs/1902.08710",
  "pdf": "https://arxiv.org/pdf/1902.08710",
  "bibtex": "@misc{engel2019_arxiv:1902.08710,\n    title = {GANSynth: Adversarial Neural Audio Synthesis},\n    author = {Jesse Engel and Kumar Krishna Agrawal and Shuo Chen and Ishaan Gulrajani and Chris Donahue and Adam Roberts},\n    year = {2019},\n    archiveprefix = {arXiv},\n    eprint = {1902.08710},\n    pdf = {https://arxiv.org/pdf/1902.08710},\n    url = {https://arxiv.org/abs/1902.08710}\n}",
  "source": "arxiv.org",
  "date": 1562146852,
  "tags": [],
  "api": "https://export.arxiv.org/api/query?id_list=1902.08710"
}