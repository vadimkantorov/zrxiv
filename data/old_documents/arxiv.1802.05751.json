{
  "title": "Image Transformer",
  "authors": [
    "Niki Parmar",
    "Ashish Vaswani",
    "Jakob Uszkoreit",
    "Łukasz Kaiser",
    "Noam Shazeer",
    "Alexander Ku",
    "Dustin Tran"
  ],
  "abstract": "  Image generation has been successfully cast as an autoregressive sequence\ngeneration or transformation problem. Recent work has shown that self-attention\nis an effective way of modeling textual sequences. In this work, we generalize\na recently proposed model architecture based on self-attention, the\nTransformer, to a sequence modeling formulation of image generation with a\ntractable likelihood. By restricting the self-attention mechanism to attend to\nlocal neighborhoods we significantly increase the size of images the model can\nprocess in practice, despite maintaining significantly larger receptive fields\nper layer than typical convolutional neural networks. While conceptually\nsimple, our generative models significantly outperform the current state of the\nart in image generation on ImageNet, improving the best published negative\nlog-likelihood on ImageNet from 3.83 to 3.77. We also present results on image\nsuper-resolution with a large magnification ratio, applying an encoder-decoder\nconfiguration of our architecture. In a human evaluation study, we find that\nimages generated by our super-resolution model fool human observers three times\nmore often than the previous state of the art.\n",
  "id": "arxiv.1802.05751",
  "url": "https://arxiv.org/abs/1802.05751",
  "pdf": "https://arxiv.org/pdf/1802.05751",
  "bibtex": "@misc{parmar2018_arxiv:1802.05751,\n    title = {Image Transformer},\n    author = {Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Łukasz Kaiser, Noam Shazeer, Alexander Ku, Dustin Tran},\n    year = {2018},\n    archiveprefix = {arXiv},\n    eprint = {1802.05751},\n    pdf = {https://arxiv.org/pdf/1802.05751},\n    url = {https://arxiv.org/abs/1802.05751}\n}",
  "source": "arxiv.org",
  "date": 1545503913,
  "tags": []
}