{
  "title": "Neural Stochastic Differential Equations: Deep Latent Gaussian Models in the Diffusion Limit",
  "authors": [
    "Belinda Tzen",
    "Maxim Raginsky"
  ],
  "abstract": "In deep latent Gaussian models, the latent variable is generated by a\ntime-inhomogeneous Markov chain, where at each time step we pass the current\nstate through a parametric nonlinear map, such as a feedforward neural net, and\nadd a small independent Gaussian perturbation. This work considers the\ndiffusion limit of such models, where the number of layers tends to infinity,\nwhile the step size and the noise variance tend to zero. The limiting latent\nobject is an It√¥ diffusion process that solves a stochastic differential\nequation (SDE) whose drift and diffusion coefficient are implemented by neural\nnets. We develop a variational inference framework for these \\textit{neural\nSDEs} via stochastic backpropagation in Wiener space, where the variational\napproximations to the posterior are obtained by Girsanov (mean-shift)\ntransformation of the standard Wiener process and the computation of gradients\nis based on the theory of stochastic flows. This permits the use of black-box\nSDE solvers and automatic differentiation for end-to-end inference.\nExperimental results with synthetic data are provided.",
  "id": "arxiv.1905.09883",
  "url": "https://arxiv.org/abs/1905.09883",
  "pdf": "https://arxiv.org/pdf/1905.09883",
  "bibtex": "@misc{tzen2019_arxiv:1905.09883,\n    title = {Neural Stochastic Differential Equations: Deep Latent Gaussian Models in the Diffusion Limit},\n    author = {Belinda Tzen and Maxim Raginsky},\n    year = {2019},\n    archiveprefix = {arXiv},\n    eprint = {1905.09883},\n    pdf = {https://arxiv.org/pdf/1905.09883},\n    url = {https://arxiv.org/abs/1905.09883}\n}",
  "source": "arxiv.org",
  "date": 1558958858,
  "tags": [],
  "api": "https://export.arxiv.org/api/query?id_list=1905.09883"
}