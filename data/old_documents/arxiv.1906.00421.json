{
  "title": "Air Learning: An AI Research Platform for Algorithm-Hardware Benchmarking of Autonomous Aerial Robots",
  "authors": [
    "Srivatsan Krishnan",
    "Behzad Borojerdian",
    "William Fu",
    "Aleksandra Faust",
    "Vijay Janapa Reddi"
  ],
  "abstract": "We introduce Air Learning, an AI research platform for benchmarking\nalgorithm-hardware performance and energy efficiency trade-offs. We focus in\nparticular on deep reinforcement learning (RL) interactions in autonomous\nunmanned aerial vehicles (UAVs). Equipped with a random environment generator,\nAirLearning exposes a UAV to a diverse set of challenging scenarios. Users can\nspecify a task, train different RL policies and evaluate their performance and\nenergy efficiency on a variety of hardware platforms. To show how Air Learning\ncan be used, we seed it with Deep Q Networks (DQN) and Proximal Policy\nOptimization (PPO) to solve a point-to-point obstacle avoidance task in three\ndifferent environments, generated using our configurable environment generator.\nWe train the two algorithms using curriculum learning and\nnon-curriculum-learning. Air Learning assesses the trained policies'\nperformance, under a variety of quality-of-flight (QoF) metrics, such as the\nenergy consumed, endurance and the average trajectory length, on\nresource-constrained embedded platforms like a Ras-Pi. We find that the\ntrajectories on an embedded Ras-Pi are vastly different from those predicted on\na high-end desktop system, resulting in up to 79.43% longer trajectories in one\nof the environments. To understand the source of such differences, we use Air\nLearning to artificially degrade desktop performance to mimic what happens on a\nlow-end embedded system. QoF metrics with hardware-in-the-loop characterize\nthose differences and expose how the choice of onboard compute affects the\naerial robot's performance. We also conduct reliability studies to demonstrate\nhow Air Learning can help understand how sensor failures affect the learned\npolicies. All put together, Air Learning enables a broad class of RL studies on\nUAVs. More information and code for Air Learning can be found here:\nhttp://bit.ly/2JNAVb6.",
  "id": "arxiv.1906.00421",
  "url": "https://arxiv.org/abs/1906.00421",
  "pdf": "https://arxiv.org/pdf/1906.00421",
  "bibtex": "@misc{krishnan2019_arxiv:1906.00421,\n    title = {Air Learning: An AI Research Platform for Algorithm-Hardware Benchmarking of Autonomous Aerial Robots},\n    author = {Srivatsan Krishnan and Behzad Borojerdian and William Fu and Aleksandra Faust and Vijay Janapa Reddi},\n    year = {2019},\n    archiveprefix = {arXiv},\n    eprint = {1906.00421},\n    pdf = {https://arxiv.org/pdf/1906.00421},\n    url = {https://arxiv.org/abs/1906.00421}\n}",
  "source": "arxiv.org",
  "date": 1561333835,
  "tags": [],
  "api": "https://export.arxiv.org/api/query?id_list=1906.00421"
}