{
  "title": "Unsupervised Data Augmentation",
  "authors": [
    "Qizhe Xie",
    "Zihang Dai",
    "Eduard Hovy",
    "Minh-Thang Luong",
    "Quoc V. Le"
  ],
  "abstract": "Despite its success, deep learning still needs large labeled datasets to\nsucceed. Data augmentation has shown much promise in alleviating the need for\nmore labeled data, but it so far has mostly been applied in supervised settings\nand achieved limited gains. In this work, we propose to apply data augmentation\nto unlabeled data in a semi-supervised learning setting. Our method, named\nUnsupervised Data Augmentation or UDA, encourages the model predictions to be\nconsistent between an unlabeled example and an augmented unlabeled example.\nUnlike previous methods that use random noise such as Gaussian noise or dropout\nnoise, UDA has a small twist in that it makes use of harder and more realistic\nnoise generated by state-of-the-art data augmentation methods. This small twist\nleads to substantial improvements on six language tasks and three vision tasks\neven when the labeled set is extremely small. For example, on the IMDb text\nclassification dataset, with only 20 labeled examples, UDA outperforms the\nstate-of-the-art model trained on 25,000 labeled examples. On standard\nsemi-supervised learning benchmarks, CIFAR-10 with 4,000 examples and SVHN with\n1,000 examples, UDA outperforms all previous approaches and reduces more than\n$30\\%$ of the error rates of state-of-the-art methods: going from 7.66% to\n5.27% and from 3.53% to 2.46% respectively. UDA also works well on datasets\nthat have a lot of labeled data. For example, on ImageNet, with 1.3M extra\nunlabeled data, UDA improves the top-1/top-5 accuracy from 78.28/94.36% to\n79.04/94.45% when compared to AutoAugment.",
  "id": "arxiv.1904.12848",
  "url": "https://arxiv.org/abs/1904.12848",
  "pdf": "https://arxiv.org/pdf/1904.12848",
  "bibtex": "@misc{xie2019_arxiv:1904.12848,\n    title = {Unsupervised Data Augmentation},\n    author = {Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},\n    year = {2019},\n    archiveprefix = {arXiv},\n    eprint = {1904.12848},\n    pdf = {https://arxiv.org/pdf/1904.12848},\n    url = {https://arxiv.org/abs/1904.12848}\n}",
  "source": "arxiv.org",
  "date": 1558291142,
  "tags": [],
  "api": "https://export.arxiv.org/api/query?id_list=1904.12848"
}