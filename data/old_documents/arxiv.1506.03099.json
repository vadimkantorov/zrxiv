{
  "title": "Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks",
  "authors": [
    "Samy Bengio",
    "Oriol Vinyals",
    "Navdeep Jaitly",
    "Noam Shazeer"
  ],
  "abstract": "Recurrent Neural Networks can be trained to produce sequences of tokens given\nsome input, as exemplified by recent results in machine translation and image\ncaptioning. The current approach to training them consists of maximizing the\nlikelihood of each token in the sequence given the current (recurrent) state\nand the previous token. At inference, the unknown previous token is then\nreplaced by a token generated by the model itself. This discrepancy between\ntraining and inference can yield errors that can accumulate quickly along the\ngenerated sequence. We propose a curriculum learning strategy to gently change\nthe training process from a fully guided scheme using the true previous token,\ntowards a less guided scheme which mostly uses the generated token instead.\nExperiments on several sequence prediction tasks show that this approach yields\nsignificant improvements. Moreover, it was used successfully in our winning\nentry to the MSCOCO image captioning challenge, 2015.",
  "id": "arxiv.1506.03099",
  "url": "https://arxiv.org/abs/1506.03099",
  "pdf": "https://arxiv.org/pdf/1506.03099",
  "bibtex": "@misc{bengio2015_arxiv:1506.03099,\n    title = {Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks},\n    author = {Samy Bengio and Oriol Vinyals and Navdeep Jaitly and Noam Shazeer},\n    year = {2015},\n    archiveprefix = {arXiv},\n    eprint = {1506.03099},\n    pdf = {https://arxiv.org/pdf/1506.03099},\n    url = {https://arxiv.org/abs/1506.03099}\n}",
  "source": "arxiv.org",
  "date": 1561646688,
  "tags": [],
  "api": "https://export.arxiv.org/api/query?id_list=1506.03099"
}