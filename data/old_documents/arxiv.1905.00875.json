{
  "title": "Self-supervised Learning for Video Correspondence Flow",
  "authors": [
    "Zihang Lai",
    "Weidi Xie"
  ],
  "abstract": "The objective of this paper is self-supervised learning of feature embeddings\nfrom videos, suitable for correspondence flow, i.e. matching correspondences\nbetween frames over the video. We leverage the natural spatial-temporal\ncoherence of appearance in videos, to create a \"pointer\" model that learns to\nreconstruct a target frame by copying colors from a reference frame.\n  We make three contributions: First, we introduce a simple information\nbottleneck that enforces the model to learn robust features for correspondence\nmatching, and avoids it learning trivial solutions, e.g. matching based on\nlow-level color information. Second, we propose to train the model over a long\ntemporal window in videos. To make the model more robust to complex object\ndeformation, occlusion, i.e. the problem of tracker drifting, we formulate a\nrecursive model, trained with scheduled sampling and cycle consistency. Third,\nwe evaluate the approach by first training on the Kinetics dataset using\nself-supervised learning, and then directly applied for DAVIS video\nsegmentation and JHMDB keypoint tracking. On both tasks, our approach has\nachieved state-of-the-art performance, especially on segmentation, we\noutperform all previous methods by a significant margin.",
  "id": "arxiv.1905.00875",
  "url": "https://arxiv.org/abs/1905.00875",
  "pdf": "https://arxiv.org/pdf/1905.00875",
  "bibtex": "@misc{lai2019_arxiv:1905.00875,\n    title = {Self-supervised Learning for Video Correspondence Flow},\n    author = {Zihang Lai and Weidi Xie},\n    year = {2019},\n    archiveprefix = {arXiv},\n    eprint = {1905.00875},\n    pdf = {https://arxiv.org/pdf/1905.00875},\n    url = {https://arxiv.org/abs/1905.00875}\n}",
  "source": "arxiv.org",
  "date": 1556922484,
  "tags": [],
  "api": "https://export.arxiv.org/api/query?id_list=1905.00875"
}